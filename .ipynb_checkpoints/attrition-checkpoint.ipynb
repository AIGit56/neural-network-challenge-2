{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alIIEHibGc3M"
   },
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "6eDUJ4NtGc3P",
    "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
       "0   41       Yes      Travel_Rarely                   Sales                 1   \n",
       "1   49        No  Travel_Frequently  Research & Development                 8   \n",
       "2   37       Yes      Travel_Rarely  Research & Development                 2   \n",
       "3   33        No  Travel_Frequently  Research & Development                 3   \n",
       "4   27        No      Travel_Rarely  Research & Development                 2   \n",
       "\n",
       "   Education EducationField  EnvironmentSatisfaction  HourlyRate  \\\n",
       "0          2  Life Sciences                        2          94   \n",
       "1          1  Life Sciences                        3          61   \n",
       "2          2          Other                        4          92   \n",
       "3          4  Life Sciences                        4          56   \n",
       "4          1        Medical                        1          40   \n",
       "\n",
       "   JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
       "0               3  ...                  3                        1   \n",
       "1               2  ...                  4                        4   \n",
       "2               2  ...                  3                        2   \n",
       "3               3  ...                  3                        3   \n",
       "4               3  ...                  3                        4   \n",
       "\n",
       "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 0                 8                      0               1   \n",
       "1                 1                10                      3               3   \n",
       "2                 0                 7                      3               3   \n",
       "3                 0                 8                      3               3   \n",
       "4                 1                 6                      3               3   \n",
       "\n",
       "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                   4                        0   \n",
       "1              10                   7                        1   \n",
       "2               0                   0                        0   \n",
       "3               8                   7                        3   \n",
       "4               2                   2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#  Import and read the attrition data\n",
    "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g22aQSY4Gc3Q",
    "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         43\n",
       "Attrition                    2\n",
       "BusinessTravel               3\n",
       "Department                   3\n",
       "DistanceFromHome            29\n",
       "Education                    5\n",
       "EducationField               6\n",
       "EnvironmentSatisfaction      4\n",
       "HourlyRate                  71\n",
       "JobInvolvement               4\n",
       "JobLevel                     5\n",
       "JobRole                      9\n",
       "JobSatisfaction              4\n",
       "MaritalStatus                3\n",
       "NumCompaniesWorked          10\n",
       "OverTime                     2\n",
       "PercentSalaryHike           15\n",
       "PerformanceRating            2\n",
       "RelationshipSatisfaction     4\n",
       "StockOptionLevel             4\n",
       "TotalWorkingYears           40\n",
       "TrainingTimesLastYear        7\n",
       "WorkLifeBalance              4\n",
       "YearsAtCompany              37\n",
       "YearsInCurrentRole          19\n",
       "YearsSinceLastPromotion     16\n",
       "YearsWithCurrManager        18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "attrition_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "50vMgBEnJbfM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attrition              Department\n",
      "0       Yes                   Sales\n",
      "1        No  Research & Development\n",
      "2       Yes  Research & Development\n",
      "3        No  Research & Development\n",
      "4        No  Research & Development\n"
     ]
    }
   ],
   "source": [
    "# Create y_df with the Attrition and Department columns\n",
    "\n",
    "y_df = attrition_df[['Attrition', 'Department']]\n",
    "print(y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Virka0zLGc3R",
    "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                          int64\n",
      "DistanceFromHome             int64\n",
      "Education                    int64\n",
      "EnvironmentSatisfaction      int64\n",
      "HourlyRate                   int64\n",
      "JobInvolvement               int64\n",
      "JobLevel                     int64\n",
      "RelationshipSatisfaction     int64\n",
      "MaritalStatus               object\n",
      "YearsAtCompany               int64\n",
      "dtype: object\n",
      "   Age  DistanceFromHome  Education  EnvironmentSatisfaction  HourlyRate  \\\n",
      "0   41                 1          2                        2          94   \n",
      "1   49                 8          1                        3          61   \n",
      "2   37                 2          2                        4          92   \n",
      "3   33                 3          4                        4          56   \n",
      "4   27                 2          1                        1          40   \n",
      "\n",
      "   JobInvolvement  JobLevel  RelationshipSatisfaction MaritalStatus  \\\n",
      "0               3         2                         1        Single   \n",
      "1               2         2                         4       Married   \n",
      "2               2         1                         2        Single   \n",
      "3               3         1                         3       Married   \n",
      "4               3         1                         4       Married   \n",
      "\n",
      "   YearsAtCompany  \n",
      "0               6  \n",
      "1              10  \n",
      "2               0  \n",
      "3               8  \n",
      "4               2  \n"
     ]
    }
   ],
   "source": [
    "# Create a list of at least 10 column names to use as X data\n",
    "selected_columns = [\n",
    "    'Age', \n",
    "    'DistanceFromHome', \n",
    "    'Education', \n",
    "    'EnvironmentSatisfaction', \n",
    "    'HourlyRate', \n",
    "    'JobInvolvement', \n",
    "    'JobLevel', \n",
    "    'RelationshipSatisfaction', \n",
    "    'MaritalStatus', \n",
    "    'YearsAtCompany'\n",
    "]\n",
    "\n",
    "# Create X_df using your selected columns\n",
    "X_df = attrition_df[selected_columns]\n",
    "\n",
    "# Show the data types for X_df\n",
    "print(X_df.dtypes)\n",
    "print(X_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "KaJfdOGUMHMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: X_train: (1176, 10), y_train: (1176, 2)\n",
      "Testing data shape: X_test: (294, 10), y_test: (294, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df,y_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Testing data shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data after transformation:\n",
      "   Age Department Attrition  MaritalStatus_Married  MaritalStatus_Single\n",
      "0   25         HR       Yes                    0.0                   1.0\n",
      "1   30         IT        No                    1.0                   0.0\n",
      "2   35      Sales       Yes                    0.0                   0.0\n",
      "\n",
      "Testing data after transformation:\n",
      "   Age Department Attrition  MaritalStatus_Married  MaritalStatus_Single\n",
      "0   25         HR       Yes                    0.0                   1.0\n",
      "1   30         IT        No                    1.0                   0.0\n",
      "2   35      Sales       Yes                    0.0                   0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberta Chandler\\AppData\\Local\\Temp\\ipykernel_10356\\1637761854.py:20: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  X_train = X_train.apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\Roberta Chandler\\AppData\\Local\\Temp\\ipykernel_10356\\1637761854.py:21: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  X_test = X_test.apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert your X data to numeric data types however you see fit\n",
    "# Add new code cells as necessary\n",
    "\n",
    "data = {'Age': [25, 30, 35],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Divorced'],\n",
    "    'Department': ['HR', 'IT', 'Sales'],\n",
    "    'Attrition': ['Yes', 'No', 'Yes']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "df['MaritalStatus'] = label_encoder.fit_transform(df['MaritalStatus'])\n",
    "df['Department'] = label_encoder.fit_transform(df['Department'])\n",
    "df['Attrition'] = label_encoder.fit_transform(df['Attrition'])\n",
    "\n",
    "\n",
    "X_train = X_train.apply(pd.to_numeric, errors='ignore')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "X_train = pd.DataFrame({'Age': [25, 30, 35],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Divorced'],\n",
    "    'Department': ['HR', 'IT', 'Sales'],\n",
    "    'Attrition': ['Yes', 'No', 'Yes']\n",
    "})\n",
    "\n",
    "X_test = pd.DataFrame({'Age': [25, 30, 35],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Divorced'],\n",
    "    'Department': ['HR', 'IT', 'Sales'],\n",
    "    'Attrition': ['Yes', 'No', 'Yes']\n",
    "})\n",
    "# Initialize the OneHotEncoder with appropriate settings\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "\n",
    "marital_status_encoded = encoder.fit_transform(df[['MaritalStatus']])\n",
    "department_encoded = encoder.fit_transform(df[['Department']])\n",
    "\n",
    "department_columns = encoder.get_feature_names_out(['Department'])\n",
    "\n",
    "department_df = pd.DataFrame(department_encoded, columns=department_columns, index=df.index)\n",
    "\n",
    "df = df.drop(columns=['MaritalStatus', 'Department'])\n",
    "\n",
    "# Ensure 'MaritalStatus' is treated as a DataFrame (2D structure)\n",
    "encoder.fit(X_train[['MaritalStatus']])\n",
    "\n",
    "# Transform the column and add it back to the DataFrame\n",
    "marital_status_train_encoded = encoder.fit_transform(X_train[['MaritalStatus']])\n",
    "marital_status_test_encoded = encoder.transform(X_test[['MaritalStatus']])\n",
    "\n",
    "\n",
    "# Convert the encoded data to a pandas DataFrame with column names\n",
    "import pandas as pd\n",
    "encoded_columns = encoder.get_feature_names_out(['MaritalStatus'])\n",
    "\n",
    "train_encoded_df = pd.DataFrame(marital_status_train_encoded, columns=encoded_columns, index=X_train.index)\n",
    "test_encoded_df = pd.DataFrame(marital_status_test_encoded, columns=encoded_columns, index=X_test.index)\n",
    "\n",
    "# Add the encoded columns to the original DataFrame and drop the original column\n",
    "X_train = pd.concat([X_train, train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_encoded_df], axis=1)\n",
    "\n",
    "X_train = X_train.drop(columns='MaritalStatus')\n",
    "X_test = X_test.drop(columns='MaritalStatus')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(\"Training data after transformation:\")\n",
    "print(X_train)\n",
    "\n",
    "print(\"\\nTesting data after transformation:\")\n",
    "print(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                        int64\n",
      "Department                object\n",
      "Attrition                 object\n",
      "MaritalStatus_Married    float64\n",
      "MaritalStatus_Single     float64\n",
      "dtype: object\n",
      "Age                        int64\n",
      "Department                object\n",
      "Attrition                 object\n",
      "MaritalStatus_Married    float64\n",
      "MaritalStatus_Single     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Transform the \"MaritalStatus\" column in both X_train and X_test\n",
    "X_train = pd.DataFrame({'Age': [25, 30, 35],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Divorced'],\n",
    "    'Department': ['HR', 'IT', 'Sales'],\n",
    "    'Attrition': ['Yes', 'No', 'Yes']\n",
    "})\n",
    "X_test = pd.DataFrame({'Age': [25, 30, 35],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Divorced'],\n",
    "    'Department': ['HR', 'IT', 'Sales'],\n",
    "    'Attrition': ['Yes', 'No', 'Yes']\n",
    "})\n",
    "\n",
    "# Create DataFrames for the encoded columns with appropriate column names\n",
    "encoded_columns = encoder.get_feature_names_out(['MaritalStatus'])\n",
    "\n",
    "train_encoded_df = pd.DataFrame(marital_status_train_encoded, columns=encoded_columns, index=X_train.index)\n",
    "test_encoded_df = pd.DataFrame(marital_status_test_encoded, columns=encoded_columns, index=X_test.index)\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrames\n",
    "X_train = pd.concat([X_train, train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original \"MaritalStatus\" column\n",
    "X_train = X_train.drop(columns='MaritalStatus')\n",
    "X_test = X_test.drop(columns='MaritalStatus')\n",
    "\n",
    "# Print the data types of the modified DataFrames\n",
    "print(X_train.dtypes)\n",
    "print(X_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Training Data:\n",
      "        Age  MaritalStatus_Married  MaritalStatus_Single\n",
      "0 -1.224745              -0.707107              1.414214\n",
      "1  0.000000               1.414214             -0.707107\n",
      "2  1.224745              -0.707107             -0.707107\n",
      "\n",
      "Scaled Testing Data:\n",
      "        Age  MaritalStatus_Married  MaritalStatus_Single\n",
      "0 -1.224745              -0.707107              1.414214\n",
      "1  0.000000               1.414214             -0.707107\n",
      "2  1.224745              -0.707107             -0.707107\n",
      "[[-1.22474487 -0.70710678  1.41421356]\n",
      " [ 0.          1.41421356 -0.70710678]\n",
      " [ 1.22474487 -0.70710678 -0.70710678]]\n",
      "[[-1.22474487 -0.70710678  1.41421356]\n",
      " [ 0.          1.41421356 -0.70710678]\n",
      " [ 1.22474487 -0.70710678 -0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# Create a StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_numeric = X_train.select_dtypes(include=['float64', 'int64'])\n",
    "X_test_numeric = X_test.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Fit the StandardScaler to the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
    "X_test_scaled = scaler.transform(X_test_numeric)\n",
    "\n",
    "# Scale the training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['float64', 'int64']))\n",
    "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_numeric.columns, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_numeric.columns, index=X_test.index)\n",
    "\n",
    "print(\"Scaled Training Data:\")\n",
    "print(X_train_scaled_df)\n",
    "\n",
    "print(\"\\nScaled Testing Data:\")\n",
    "print(X_test_scaled_df)\n",
    "\n",
    "print(X_train_scaled)\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OneHotEncoder with desired settings\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the \"MaritalStatus\" column in X_train\n",
    "Marital_status_encoded = encoder.fit(np.array(X_df['MaritalStatus']).reshape(-1, 1))\n",
    "\n",
    "\n",
    "#marital_status_encoded = pd.DataFrame(marital_status_encoded, columns=encoder.get_feature_names_out(['MaritalStatus']), index=X_train.index)\n",
    "#marital_status_encoded = encoder.fit_transform(X_df[['MaritalStatus']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z0Mky8vQSz4",
    "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "\n",
    "X_train = pd.DataFrame({'Age': [25, 30, 35],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Divorced'],\n",
    "    'Department': ['HR', 'IT', 'Sales'],\n",
    "    'Attrition': ['Yes', 'No', 'Yes']\n",
    "})\n",
    "X_test = pd.DataFrame({'Age': [25, 30, 35],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Divorced'],\n",
    "    'Department': ['HR', 'IT', 'Sales'],\n",
    "    'Attrition': ['Yes', 'No', 'Yes']\n",
    "})\n",
    "\n",
    "\n",
    "# Create a OneHotEncoder for the Department column\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "#encoder = OneHotEncoder(drop=None)\n",
    "y_train_department = encoder.fit_transform(X_train[['Department']])  \n",
    "y_test_department = encoder.transform(X_test[['Department']])\n",
    "\n",
    "# Fit the encoder to the training data\n",
    "encoder.fit(np.array(y_train['Department']).reshape(-1, 1))\n",
    "\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "y_train_department = encoder.transform(np.array(y_train['Department']).reshape(-1, 1))\n",
    "y_test_department = encoder.transform(np.array(y_test['Department']).reshape(-1, 1))\n",
    "\n",
    "print(y_train_department[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-G4DSpvFRrk4",
    "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a OneHotEncoder for the Attrition column\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "encoder = OneHotEncoder(drop=None)\n",
    "\n",
    "# Fit the encoder to the training data\n",
    "encoder.fit(np.array(y_train['Attrition']).reshape(-1, 1))\n",
    "\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "y_train_attrition = encoder.transform(np.array(y_train['Attrition']).reshape(-1, 1))\n",
    "y_test_attrition = encoder.transform(np.array(y_test['Attrition']).reshape(-1, 1))\n",
    "\n",
    "print(y_train_attrition[:5])\n",
    "\n",
    "#y_train_attrition = (X_train['Attrition'] == 'Yes').astype(int)\n",
    "#y_test_attrition = (X_test['Attrition'] == 'Yes').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykNmu_WWGc3T"
   },
   "source": [
    "## Create, Compile, and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "WUptZqmSGc3T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in X_train: 4\n"
     ]
    }
   ],
   "source": [
    "# Find the number of columns in the X training data\n",
    "num_columns = len(X_train.columns)\n",
    "print(f\"Number of columns in X_train: {num_columns}\")\n",
    "\n",
    "# Create the input layer\n",
    "input_layer = layers.Input(shape=(X_train.shape[1],))\n",
    "#input_layer = layers.Input(shape = (num_columns,), name='input_features')\n",
    "\n",
    "# Create at least two shared layers\n",
    "shared_layer1 = layers.Dense(64, activation='relu')(input_layer)\n",
    "shared_layer2 = layers.Dense(32, activation='relu')(shared_layer1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a branch to predict the department target column\n",
    "# with a hidden layer and an output layer\n",
    "hidden_department = layers.Dense(32, activation='relu', name='hidden_department')(shared_layer2)\n",
    "output_department = layers.Dense(y_train_department.shape[1], activation='sigmoid', name='output_department')(hidden_department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a branch to predict the attrition target column\n",
    "# with a hidden layer and an output layer\n",
    "hidden_attrition = layers.Dense(32, activation='relu', name='hidden_attrition')(shared_layer2)\n",
    "output_attrition = layers.Dense(y_train_attrition.shape[1], activation='sigmoid', name='output_attrition')(hidden_attrition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twmuejdxGc3T",
    "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create the model\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nfrom keras.optimizers import Adam\\nimport matplotlib.pyplot as plt\\n\\ninputs = Input(shape=(X_train.shape[1],))\\nx = Dense(64, activation='relu')(inputs)\\noutput_department = Dense(1, activation='sigmoid', name='output_department')(x)\\noutput_attrition = Dense(1, activation='sigmoid', name='output_attrition')(x)\\n\\nnum_features = X_train.shape[1]\\nmain_input = layers.Input(shape=(num_features,), name='main_input')\\nmain_output = layers.Input(shape=(num_features,), name='secondary_input')\\n\\ndepartment_input = layers.Input(shape=(1,), name='department_input')\\ndepartment_layer1 = layers.Dense(64, activation='relu')(department_input)\\ndepartment_layer2 = layers.Dense(32, activation='relu')(department_layer1)\\ndepartment_layer3 = layers.Dropout(0.2)(department_layer2)\\ndepartment_layer4 = layers.Dense(16, activation='relu')(department_layer3)\\ndepartment_layer5 = layers.Dropout(0.2)(department_layer4)\\noutput_department = layers.Dense(1, activation='sigmoid', name='output_department')(department_layer5)\\n\\nmodel = Model(inputs=inputs, outputs=[output_department, output_attrition])\\n\\nmodel = tf.keras.Model(\\n    inputs=[main_input, main_output, department_input], \\n    outputs=[main_input, output_department]\\n)\\n\\n# Compile the model\\nmodel.compile(\\n    optimizer=Adam(),\\n    loss={\\n        'output_department': 'categorical_crossentropy',\\n        'output_attrition': 'binary_crossentropy'\\n    },\\n    metrics={\\n        'output_department': 'accuracy',\\n        'output_attrition': 'accuracy'\\n    }\\n)\\n\\nfit_model = model.fit(\\n    X_train,\\n    {'output_department': y_train_department, 'output_attrition': y_train_attrition}, \\n    epochs=10, \\n    batch_size=32\\n)\\n# Summarize the model\\nmodel.summary()\""
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Create the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "output_department = Dense(1, activation='sigmoid', name='output_department')(x)\n",
    "output_attrition = Dense(1, activation='sigmoid', name='output_attrition')(x)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "main_input = layers.Input(shape=(num_features,), name='main_input')\n",
    "main_output = layers.Input(shape=(num_features,), name='secondary_input')\n",
    "\n",
    "department_input = layers.Input(shape=(1,), name='department_input')\n",
    "department_layer1 = layers.Dense(64, activation='relu')(department_input)\n",
    "department_layer2 = layers.Dense(32, activation='relu')(department_layer1)\n",
    "department_layer3 = layers.Dropout(0.2)(department_layer2)\n",
    "department_layer4 = layers.Dense(16, activation='relu')(department_layer3)\n",
    "department_layer5 = layers.Dropout(0.2)(department_layer4)\n",
    "output_department = layers.Dense(1, activation='sigmoid', name='output_department')(department_layer5)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[output_department, output_attrition])\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[main_input, main_output, department_input], \n",
    "    outputs=[main_input, output_department]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss={\n",
    "        'output_department': 'categorical_crossentropy',\n",
    "        'output_attrition': 'binary_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'output_department': 'accuracy',\n",
    "        'output_attrition': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "fit_model = model.fit(\n",
    "    X_train,\n",
    "    {'output_department': y_train_department, 'output_attrition': y_train_attrition}, \n",
    "    epochs=10, \n",
    "    batch_size=32\n",
    ")\n",
    "# Summarize the model\n",
    "model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nfrom scipy.sparse import csr_matrix\\nimport tensorflow as tf\\nfrom keras.models import Model\\nfrom keras.layers import Input, Dense\\nfrom keras.optimizers import Adam\\n\\n#y_train_department_dense = y_train_department.toarray()  \\n#y_train_attrition_dense = y_train_attrition.toarray()  \\n\\n#print(f\"y_train_department_dense shape:\", y_train_department_dense.shape)  # Should be (num_samples, 1)\\n#print(f\"y_train_attrition_dense shape:\", y_train_attrition_dense.shape)  # Should be (num_samples, 1)\\n\\ny_train_department_dense = y_train_department_dense.reshape(-1, 1)  # Reshape if necessary\\ny_train_attrition_dense = y_train_attrition_dense.reshape(-1, 1)  # Reshape if necessary\\n\\nprint(f\"y_train_department_dense shape after reshape: {y_train_department_dense.shape}\")\\nprint(f\"y_train_attrition_dense shape after reshape: {y_train_attrition_dense.shape}\")'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#y_train_department_dense = y_train_department.toarray()  \n",
    "#y_train_attrition_dense = y_train_attrition.toarray()  \n",
    "\n",
    "#print(f\"y_train_department_dense shape:\", y_train_department_dense.shape)  # Should be (num_samples, 1)\n",
    "#print(f\"y_train_attrition_dense shape:\", y_train_attrition_dense.shape)  # Should be (num_samples, 1)\n",
    "\n",
    "y_train_department_dense = y_train_department_dense.reshape(-1, 1)  # Reshape if necessary\n",
    "y_train_attrition_dense = y_train_attrition_dense.reshape(-1, 1)  # Reshape if necessary\n",
    "\n",
    "print(f\"y_train_department_dense shape after reshape: {y_train_department_dense.shape}\")\n",
    "print(f\"y_train_attrition_dense shape after reshape: {y_train_attrition_dense.shape}\")\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_department   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_attrition    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m320\u001b[0m │ input_layer_21[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_department   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_attrition    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m450\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m450\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from scipy.sparse import csr_matrix\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "output_department = Dense(1, activation='sigmoid', name='output_department')(x)\n",
    "output_attrition = Dense(1, activation='sigmoid', name='output_attrition')(x)\n",
    "\n",
    "y_train_department_dense = y_train_department.reshape(-1, 1)\n",
    "y_train_attrition_dense = y_train_attrition.reshape(-1, 1)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=[output_department, output_attrition])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss={\n",
    "        'output_department': 'categorical_crossentropy',\n",
    "        'output_attrition': 'binary_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'output_department': 'accuracy',\n",
    "        'output_attrition': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "#fit_model = model.fit(\n",
    "    #X_train,\n",
    "    #{'output_department': y_train_department_dense, 'output_attrition': y_train_attrition_dense}, \n",
    "    #epochs=10, \n",
    "    #batch_size=32\n",
    "#)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled.shape)  # Ensure this is (num_samples, num_features)\n",
    "print(y_train_department.shape)  # Should be (num_samples,)\n",
    "print(y_train_attrition.shape)  # Should be (num_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_attrition_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_department_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8oGy0dpGc3U",
    "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model, X_train_data, y_train_data, X_val_data, y_val_data):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsMoaQlgGc3U",
    "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model with the testing data\n",
    "test_results = model.evaluate(X_test,{'output_department': y_test, 'output_attrition':})\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlCtlHi0Vt54",
    "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
   },
   "outputs": [],
   "source": [
    "# Print the accuracy for both department and attrition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSyfsZfWOQM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In the provided space below, briefly answer the following questions.\n",
    "\n",
    "1. Is accuracy the best metric to use on this data? Why or why not?\n",
    "\n",
    "2. What activation functions did you choose for your output layers, and why?\n",
    "\n",
    "3. Can you name a few ways that this model might be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi9SLpFnWvbF"
   },
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
