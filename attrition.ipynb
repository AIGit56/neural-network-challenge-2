{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alIIEHibGc3M"
   },
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "6eDUJ4NtGc3P",
    "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
       "0   41       Yes      Travel_Rarely                   Sales                 1   \n",
       "1   49        No  Travel_Frequently  Research & Development                 8   \n",
       "2   37       Yes      Travel_Rarely  Research & Development                 2   \n",
       "3   33        No  Travel_Frequently  Research & Development                 3   \n",
       "4   27        No      Travel_Rarely  Research & Development                 2   \n",
       "\n",
       "   Education EducationField  EnvironmentSatisfaction  HourlyRate  \\\n",
       "0          2  Life Sciences                        2          94   \n",
       "1          1  Life Sciences                        3          61   \n",
       "2          2          Other                        4          92   \n",
       "3          4  Life Sciences                        4          56   \n",
       "4          1        Medical                        1          40   \n",
       "\n",
       "   JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
       "0               3  ...                  3                        1   \n",
       "1               2  ...                  4                        4   \n",
       "2               2  ...                  3                        2   \n",
       "3               3  ...                  3                        3   \n",
       "4               3  ...                  3                        4   \n",
       "\n",
       "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 0                 8                      0               1   \n",
       "1                 1                10                      3               3   \n",
       "2                 0                 7                      3               3   \n",
       "3                 0                 8                      3               3   \n",
       "4                 1                 6                      3               3   \n",
       "\n",
       "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                   4                        0   \n",
       "1              10                   7                        1   \n",
       "2               0                   0                        0   \n",
       "3               8                   7                        3   \n",
       "4               2                   2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#  Import and read the attrition data\n",
    "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g22aQSY4Gc3Q",
    "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         43\n",
       "Attrition                    2\n",
       "BusinessTravel               3\n",
       "Department                   3\n",
       "DistanceFromHome            29\n",
       "Education                    5\n",
       "EducationField               6\n",
       "EnvironmentSatisfaction      4\n",
       "HourlyRate                  71\n",
       "JobInvolvement               4\n",
       "JobLevel                     5\n",
       "JobRole                      9\n",
       "JobSatisfaction              4\n",
       "MaritalStatus                3\n",
       "NumCompaniesWorked          10\n",
       "OverTime                     2\n",
       "PercentSalaryHike           15\n",
       "PerformanceRating            2\n",
       "RelationshipSatisfaction     4\n",
       "StockOptionLevel             4\n",
       "TotalWorkingYears           40\n",
       "TrainingTimesLastYear        7\n",
       "WorkLifeBalance              4\n",
       "YearsAtCompany              37\n",
       "YearsInCurrentRole          19\n",
       "YearsSinceLastPromotion     16\n",
       "YearsWithCurrManager        18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "attrition_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "50vMgBEnJbfM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attrition              Department\n",
      "0       Yes                   Sales\n",
      "1        No  Research & Development\n",
      "2       Yes  Research & Development\n",
      "3        No  Research & Development\n",
      "4        No  Research & Development\n"
     ]
    }
   ],
   "source": [
    "# Create y_df with the Attrition and Department columns\n",
    "\n",
    "y_df = attrition_df[['Attrition', 'Department']]\n",
    "print(y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Virka0zLGc3R",
    "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                          int64\n",
      "Department                  object\n",
      "DistanceFromHome             int64\n",
      "Education                    int64\n",
      "MaritalStatus               object\n",
      "EnvironmentSatisfaction      int64\n",
      "HourlyRate                   int64\n",
      "JobInvolvement               int64\n",
      "Attrition                   object\n",
      "RelationshipSatisfaction     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a list of at least 10 column names to use as X data\n",
    "features_columns = [\n",
    "    'Age', \n",
    "    'Department',\n",
    "    'DistanceFromHome', \n",
    "    'Education', \n",
    "    'MaritalStatus',\n",
    "    'EnvironmentSatisfaction', \n",
    "    'HourlyRate', \n",
    "    'JobInvolvement', \n",
    "    'Attrition', \n",
    "    'RelationshipSatisfaction'\n",
    "]\n",
    "\n",
    "# Create X_df using your selected columns\n",
    "X_df = attrition_df[features_columns]\n",
    "\n",
    "# Show the data types for X_df\n",
    "print(X_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  DistanceFromHome  Education MaritalStatus  EnvironmentSatisfaction  \\\n",
      "0   41                 1          2        Single                        2   \n",
      "1   49                 8          1       Married                        3   \n",
      "2   37                 2          2        Single                        4   \n",
      "3   33                 3          4       Married                        4   \n",
      "4   27                 2          1       Married                        1   \n",
      "\n",
      "   HourlyRate  JobInvolvement  RelationshipSatisfaction  \n",
      "0          94               3                         1  \n",
      "1          61               2                         4  \n",
      "2          92               2                         2  \n",
      "3          56               3                         3  \n",
      "4          40               3                         4  \n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataset has a column for 'Department' and 'Attrition'\n",
    "# Now drop these columns from X_df to ensure X_df only contains features\n",
    "X_df = X_df.drop(columns=['Department', 'Attrition'])\n",
    "\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "KaJfdOGUMHMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176, 8)\n",
      "(1176, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# After splitting, make sure X_train and y_train have the same number of samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age\n",
      "0   25\n",
      "1   30\n",
      "2   35\n",
      "3   45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert your X data to numeric data types however you see fit\n",
    "# Add new code cells as necessary\n",
    "# Convert all numeric columns to numeric data type (if needed)\n",
    "\n",
    "data = {'Age': [25, 30, 35, 45],\n",
    "    'MaritalStatus': ['Single', 'Married', 'Single', 'Married']}\n",
    "\n",
    "X_df = pd.DataFrame(data)\n",
    "\n",
    "X_df = X_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Initialize the OneHotEncoder with appropriate settings\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Ensure 'MaritalStatus' is treated as a DataFrame (2D structure)\n",
    "marital_status_column = X_df[['MaritalStatus']]\n",
    "\n",
    "# Transform the column and add it back to the DataFrame\n",
    "encoded_marital_status = encoder.fit_transform(marital_status_column)\n",
    "\n",
    "# Convert the encoded data to a pandas DataFrame with column names\n",
    "encoded_df = pd.DataFrame(encoded_marital_status, columns=encoder.get_feature_names_out(['MaritalStatus']))\n",
    "\n",
    "# Add the encoded columns to the original DataFrame and drop the original column\n",
    "X_df = pd.concat([X_df, encoded_df], axis=1)\n",
    "X_df = X_df.drop(columns=['MaritalStatus'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of X_train:\n",
      "Age                       int64\n",
      "MaritalStatus_Single    float64\n",
      "dtype: object\n",
      "\n",
      "Data types of X_test:\n",
      "Age                       int64\n",
      "MaritalStatus_Single    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#Transform the \"MaritalStatus\" column in both X_train and X_test\n",
    "X_train = pd.DataFrame({'Age': [25, 30, 35, 40],\n",
    "                        'MaritalStatus': ['Single', 'Married', 'Single', 'Married']})\n",
    "X_test = pd.DataFrame({'Age': [28, 32, 38, 45],\n",
    "                       'MaritalStatus': ['Married', 'Single', 'Married', 'Single']})\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "encoded_train = encoder.fit_transform(X_train[['MaritalStatus']])\n",
    "encoded_test = encoder.transform(X_test[['MaritalStatus']])\n",
    "\n",
    "# Create DataFrames for the encoded columns with appropriate column names\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(['MaritalStatus']))\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(['MaritalStatus']))\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrames\n",
    "X_train = pd.concat([X_train, encoded_train_df], axis=1)\n",
    "X_test = pd.concat([X_test, encoded_test_df], axis=1)\n",
    "\n",
    "# Drop the original \"MaritalStatus\" column\n",
    "X_train = X_train.drop(columns='MaritalStatus')\n",
    "X_test = X_test.drop(columns='MaritalStatus')\n",
    "\n",
    "# Print the data types of the modified DataFrames\n",
    "print(\"Data types of X_train:\")\n",
    "print(X_train.dtypes)\n",
    "print(\"\\nData types of X_test:\")\n",
    "print(X_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X_train:\n",
      "        Age  MaritalStatus_Married  MaritalStatus_Single\n",
      "0 -1.341641                   -1.0                   1.0\n",
      "1 -0.447214                    1.0                  -1.0\n",
      "2  0.447214                   -1.0                   1.0\n",
      "3  1.341641                    1.0                  -1.0\n",
      "\n",
      "Scaled X_test:\n",
      "        Age  MaritalStatus_Married  MaritalStatus_Single\n",
      "0 -0.804984                    1.0                  -1.0\n",
      "1 -0.089443                   -1.0                   1.0\n",
      "2  0.983870                    1.0                  -1.0\n",
      "3  2.236068                   -1.0                   1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler\n",
    "X_train = pd.DataFrame({'Age': [25, 30, 35, 40],\n",
    "                        'MaritalStatus_Married': [0, 1, 0, 1],\n",
    "                        'MaritalStatus_Single': [1, 0, 1, 0]})\n",
    "X_test = pd.DataFrame({'Age': [28, 32, 38, 45],\n",
    "                       'MaritalStatus_Married': [1, 0, 1, 0],\n",
    "                       'MaritalStatus_Single': [0, 1, 0, 1]})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the training and testing data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "\n",
    "print(\"Scaled X_train:\")\n",
    "print(X_train_scaled_df)\n",
    "print(\"\\nScaled X_test:\")\n",
    "print(X_test_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  MaritalStatus_Single\n",
      "0   25                   1.0\n",
      "1   30                   0.0\n",
      "2   35                   1.0\n",
      "3   40                   0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.DataFrame({'Age': [25, 30, 35, 40],\n",
    "                        'MaritalStatus': ['Single', 'Married', 'Single', 'Married']})\n",
    "\n",
    "# Initialize the OneHotEncoder with desired settings\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit the encoder on the \"MaritalStatus\" column in X_train\n",
    "encoder.fit(X_train[['MaritalStatus']])\n",
    "encoded_train = encoder.transform(X_train[['MaritalStatus']])\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(['MaritalStatus']))\n",
    "X_train_encoded = pd.concat([X_train, encoded_train_df], axis=1)\n",
    "X_train_encoded = X_train_encoded.drop(columns=['MaritalStatus'])\n",
    "\n",
    "print(X_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z0Mky8vQSz4",
    "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X_train:\n",
      "   Age Attrition  Department_IT  Department_Sales\n",
      "0   25       Yes            1.0               0.0\n",
      "1   30        No            0.0               1.0\n",
      "2   35        No            0.0               0.0\n",
      "3   40       Yes            0.0               1.0\n",
      "\n",
      "Encoded X_test:\n",
      "   Age Attrition  Department_IT  Department_Sales\n",
      "0   28        No            1.0               0.0\n",
      "1   32       Yes            0.0               1.0\n",
      "2   38        No            0.0               0.0\n",
      "3   45       Yes            0.0               1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Attrition': ['Yes', 'No', 'No', 'Yes'],\n",
    "    'Department': ['IT', 'Sales', 'HR', 'Sales']\n",
    "})\n",
    "\n",
    "X_test = pd.DataFrame({\n",
    "    'Age': [28, 32, 38, 45],\n",
    "    'Attrition': ['No', 'Yes', 'No', 'Yes'],\n",
    "    'Department': ['IT', 'Sales', 'HR', 'Sales']\n",
    "})\n",
    "\n",
    "# Create a OneHotEncoder for the Department column\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit the encoder to the training data\n",
    "encoder.fit(X_train[['Department']])\n",
    "encoded_train = encoder.transform(X_train[['Department']])\n",
    "encoded_test = encoder.transform(X_test[['Department']])\n",
    "\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(['Department']))\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(['Department']))\n",
    "X_train_encoded = pd.concat([X_train, encoded_train_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test, encoded_test_df], axis=1)\n",
    "X_train_encoded = X_train_encoded.drop(columns=['Department'])\n",
    "X_test_encoded = X_test_encoded.drop(columns=['Department'])\n",
    "\n",
    "print(\"Encoded X_train:\")\n",
    "print(X_train_encoded)\n",
    "\n",
    "print(\"\\nEncoded X_test:\")\n",
    "print(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-G4DSpvFRrk4",
    "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X_train:\n",
      "   Age Department  Attrition_Yes\n",
      "0   25         IT            1.0\n",
      "1   30      Sales            0.0\n",
      "2   35         HR            0.0\n",
      "3   40      Sales            1.0\n",
      "\n",
      "Encoded X_test:\n",
      "   Age Department  Attrition_Yes\n",
      "0   28         IT            0.0\n",
      "1   32      Sales            1.0\n",
      "2   38         HR            0.0\n",
      "3   45      Sales            1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a OneHotEncoder for the Attrition column\n",
    "X_train = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Attrition': ['Yes', 'No', 'No', 'Yes'],\n",
    "    'Department': ['IT', 'Sales', 'HR', 'Sales']\n",
    "})\n",
    "\n",
    "X_test = pd.DataFrame({\n",
    "    'Age': [28, 32, 38, 45],\n",
    "    'Attrition': ['No', 'Yes', 'No', 'Yes'],\n",
    "    'Department': ['IT', 'Sales', 'HR', 'Sales']\n",
    "})\n",
    "\n",
    "# Create a OneHotEncoder for the Attrition column\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit the encoder to the training data\n",
    "encoder.fit(X_train[['Attrition']])\n",
    "encoded_train = encoder.transform(X_train[['Attrition']])\n",
    "encoded_test = encoder.transform(X_test[['Attrition']])\n",
    "\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(['Attrition']))\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(['Attrition']))\n",
    "X_train_encoded = pd.concat([X_train, encoded_train_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test, encoded_test_df], axis=1)\n",
    "X_train_encoded = X_train_encoded.drop(columns=['Attrition'])\n",
    "X_test_encoded = X_test_encoded.drop(columns=['Attrition'])\n",
    "\n",
    "\n",
    "print(\"Encoded X_train:\")\n",
    "print(X_train_encoded)\n",
    "\n",
    "print(\"\\nEncoded X_test:\")\n",
    "print(X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykNmu_WWGc3T"
   },
   "source": [
    "## Create, Compile, and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "WUptZqmSGc3T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in X_train: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_146 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_147 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_148 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,433</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,433\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,433</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,433\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "X_train = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Attrition_Yes': [1, 0, 0, 1],\n",
    "    'Department_IT': [0, 1, 1, 0],\n",
    "    'Department_HR': [1, 0, 0, 1]\n",
    "})\n",
    "\n",
    "# Find the number of columns in the X training data\n",
    "num_columns = X_train.shape[1]\n",
    "print(f\"Number of columns in X_train: {num_columns}\")\n",
    "\n",
    "# Create the input layer\n",
    "input_layer = layers.Input(shape=(num_columns,))\n",
    "\n",
    "# Create at least two shared layers\n",
    "x = layers.Dense(64, activation='relu')(input_layer)  \n",
    "x = layers.Dense(32, activation='relu')(x)            \n",
    "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a branch to predict the department target column\n",
    "# with a hidden layer and an output layer\n",
    "x_department = layers.Dense(64, activation='relu')(input_layer)  \n",
    "output_department = layers.Dense(3, activation='softmax')(x_department)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a branch to predict the attrition target column\n",
    "# with a hidden layer and an output layer\n",
    "x_attrition = layers.Dense(64, activation='relu')(input_layer)  # Hidden layer\n",
    "output_attrition = layers.Dense(1, activation='sigmoid')(x_attrition)  # Output layer for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ department_output   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │ dense_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attrition_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_153 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m320\u001b[0m │ input_layer_30[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_155 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m320\u001b[0m │ input_layer_30[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_154 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_156 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ department_output   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m99\u001b[0m │ dense_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attrition_output    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,932</span> (19.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,932\u001b[0m (19.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,932</span> (19.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,932\u001b[0m (19.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Attrition_Yes': [1, 0, 0, 1],\n",
    "    'Department_IT': [0, 1, 1, 0],\n",
    "    'Department_HR': [1, 0, 0, 1]\n",
    "})\n",
    "\n",
    "department_labels_test = ['HR', 'IT', 'IT', 'HR']\n",
    "y_department_test = pd.get_dummies(department_labels_test)  \n",
    "\n",
    "y_attrition_test = [1, 0, 0, 1]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_department_test = np.array(y_department)\n",
    "y_attrition_test = np.array(y_attrition)\n",
    "\n",
    "# Create the model\n",
    "input_layer = layers.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "department_branch = layers.Dense(64, activation='relu')(input_layer)\n",
    "department_branch = layers.Dense(32, activation='relu')(department_branch)\n",
    "department_output = layers.Dense(3, activation='softmax', name='department_output')(department_branch)\n",
    "\n",
    "attrition_branch = layers.Dense(64, activation='relu')(input_layer)\n",
    "attrition_branch = layers.Dense(32, activation='relu')(attrition_branch)\n",
    "attrition_output = layers.Dense(1, activation='sigmoid', name='attrition_output')(attrition_branch)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=[department_output, attrition_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam',\n",
    "              loss={'department_output': 'categorical_crossentropy', 'attrition_output': 'binary_crossentropy'},\n",
    "              metrics={'department_output': 'accuracy', 'attrition_output': 'accuracy'})\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8oGy0dpGc3U",
    "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model, X_train_data, y_train_data, X_val_data, y_val_data):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsMoaQlgGc3U",
    "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=   Age  Attrition_Yes  Department_IT  Department_HR\n0   28              0              1              0\n1   45              1              0              1\n2   38              1              1              0\n3   50              0              0              1 (of type <class 'pandas.core.frame.DataFrame'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[249], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m y_department_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(department_labels_test)\n\u001b[0;32m     18\u001b[0m y_attrition_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m test_loss, department_test_acc, attrition_test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, [y_department_test, y_attrition_test])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepartment Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepartment_test_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Roberta Chandler\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Roberta Chandler\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py:120\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[1;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized data type: x=   Age  Attrition_Yes  Department_IT  Department_HR\n0   28              0              1              0\n1   45              1              0              1\n2   38              1              1              0\n3   50              0              0              1 (of type <class 'pandas.core.frame.DataFrame'>)"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the testing data\n",
    "X_train = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Attrition_Yes': [1, 0, 0, 1],\n",
    "    'Department_IT': [0, 1, 1, 0],\n",
    "    'Department_HR': [1, 0, 0, 1]\n",
    "})\n",
    "    \n",
    "X_test = pd.DataFrame({\n",
    "    'Age': [28, 45, 38, 50],\n",
    "    'Attrition_Yes': [0, 1, 1, 0],\n",
    "    'Department_IT': [1, 0, 1, 0],\n",
    "    'Department_HR': [0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "department_labels_test = ['IT', 'HR', 'IT', 'HR']\n",
    "y_department_test = pd.get_dummies(department_labels_test)\n",
    "y_attrition_test = [0, 1, 1, 0]\n",
    "\n",
    "test_loss, department_test_acc, attrition_test_acc = model.evaluate(X_test, [y_department_test, y_attrition_test])\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Department Accuracy: {department_test_acc}\")\n",
    "print(f\"Attrition Accuracy: {attrition_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlCtlHi0Vt54",
    "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'department_test_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[228], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print the accuracy for both department and attrition\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepartment accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepartment_test_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttrition accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattrition_test_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'department_test_acc' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the accuracy for both department and attrition\n",
    "print(f\"Department accuracy: {department_test_acc}\")\n",
    "print(f\"Attrition accuracy: {attrition_test_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSyfsZfWOQM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In the provided space below, briefly answer the following questions.\n",
    "\n",
    "1. Is accuracy the best metric to use on this data? Why or why not?\n",
    "\n",
    "2. What activation functions did you choose for your output layers, and why?\n",
    "\n",
    "3. Can you name a few ways that this model might be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi9SLpFnWvbF"
   },
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. Accuracy is not the best metric to use because the datasets are different\n",
    "2. I chose the sigmoid function because it's best used for binary classifications that predicts one of two answers.\n",
    "3. This model can be improved if the fit the model was better explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
